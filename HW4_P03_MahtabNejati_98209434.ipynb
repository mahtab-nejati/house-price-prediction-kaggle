{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahtab Nejati\n",
    "# 98209434\n",
    "# Problem 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PoissonRegressor,TweedieRegressor,GammaRegressor,LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./q3/train.csv',index_col='Id')\n",
    "test_df = pd.read_csv('./q3/test.csv',index_col='Id')\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2&3. Cleaning data & preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTICE\n",
    "### Since the test data does not include the results, I have decided to split the train data into two chuncks, train and validation. This helps to evaluate the model at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , validation_df = train_test_split(train_df,test_size = 0.2)\n",
    "train = train_df.copy()\n",
    "validation = validation_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "## Notice \n",
    "### I have made the assumption that at the time of cleaning the data, only the training data is available. That's why I have saved the mean and range value of each feature so that I would normalize the validatoin and test data with the same parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Numerical Features Normalization: according to the description file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Nan\n",
    "### Only Normalizing MSSubClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_numerics = ['MSSubClass',\n",
    "                     'OverallQual',\n",
    "                     'OverallCond',\n",
    "                     'MoSold']\n",
    "\n",
    "train['MSSubClass'] = ((train['MSSubClass']/10)-1.5)*2\n",
    "validation['MSSubClass'] = ((validation['MSSubClass']/10)-1.5)*2\n",
    "test['MSSubClass'] = ((test['MSSubClass']/10)-1.5)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Number Numerical Features Normalization: according to the description file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t### NaN-Containing Columns:\n",
      "\n",
      "BsmtFinSF1\tBsmtFinSF2\tBsmtFullBath\tBsmtHalfBath\tBsmtUnfSF\tGarageArea\tGarageCars\tGarageYrBlt\tLotFrontage\tMasVnrArea\tTotalBsmtSF\n"
     ]
    }
   ],
   "source": [
    "real_numerics = ['LotFrontage',\n",
    "                 'LotArea',\n",
    "                 'YearBuilt',\n",
    "                 'YearRemodAdd',\n",
    "                 'MasVnrArea',\n",
    "                 'BsmtFinSF1',\n",
    "                 'BsmtFinSF2',\n",
    "                 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF',\n",
    "                 '1stFlrSF',\n",
    "                 '2ndFlrSF',\n",
    "                 'LowQualFinSF',\n",
    "                 'GrLivArea',\n",
    "                 'BsmtFullBath',\n",
    "                 'BsmtHalfBath',\n",
    "                 'FullBath',\n",
    "                 'HalfBath',\n",
    "                 'BedroomAbvGr',\n",
    "                 'KitchenAbvGr',\n",
    "                 'TotRmsAbvGrd',\n",
    "                 'Fireplaces',\n",
    "                 'GarageYrBlt',\n",
    "                 'GarageCars',\n",
    "                 'GarageArea',\n",
    "                 'WoodDeckSF',\n",
    "                 'OpenPorchSF',\n",
    "                 'EnclosedPorch',\n",
    "                 '3SsnPorch',\n",
    "                 'ScreenPorch',\n",
    "                 'PoolArea',\n",
    "                 'MiscVal',\n",
    "                 'YrSold']\n",
    "\n",
    "\n",
    "isNan_dict = {'train':[],\n",
    "              'validation':[],\n",
    "              'test':[]}\n",
    "\n",
    "for col in real_numerics:\n",
    "    if(train_df[col].isnull().values.any()):\n",
    "        isNan_dict['train'].append(col)\n",
    "    if(validation_df[col].isnull().values.any()):\n",
    "        isNan_dict['validation'].append(col)\n",
    "    if(test_df[col].isnull().values.any()):\n",
    "        isNan_dict['test'].append(col)\n",
    "\n",
    "isNan = list(set(isNan_dict['train']+isNan_dict['validation']+isNan_dict['test']))\n",
    "isNan.sort()\n",
    "print('\\n\\t### NaN-Containing Columns:\\n')\n",
    "print('\\t'.join(isNan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtFinSF1\tBsmtFinSF2\tBsmtFullBath\tBsmtHalfBath\tBsmtUnfSF\tTotalBsmtSF: \n",
    "#### NaN could mean there is no basement or the basement has no bathroom in the building. So fill with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillnan_cols = ['BsmtFinSF1','BsmtFinSF2','BsmtFullBath','BsmtHalfBath','BsmtUnfSF','TotalBsmtSF']\n",
    "for col in fillnan_cols:\n",
    "    train[col].fillna(0,inplace=True)\n",
    "    validation[col].fillna(0,inplace=True)\n",
    "    test[col].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageArea\tGarageCars\tGarageYrBlt: \n",
    "#### NaN could mean there is no garage in the building. So fill with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillnan_cols = ['GarageArea','GarageCars','GarageYrBlt']\n",
    "for col in fillnan_cols:\n",
    "    train[col].fillna(0,inplace=True)\n",
    "    validation[col].fillna(0,inplace=True)\n",
    "    test[col].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotFrontage:\n",
    "#### NaN could mean there is no lot in the building. So fill with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'].fillna(0,inplace=True)\n",
    "validation['LotFrontage'].fillna(0,inplace=True)\n",
    "test['LotFrontage'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasVnrArea:\n",
    "#### NaN could mean there is no mansor veneer wall in the building. So fill with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MasVnrArea'].fillna(0,inplace=True)\n",
    "validation['MasVnrArea'].fillna(0,inplace=True)\n",
    "test['MasVnrArea'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Rnge Normalization\n",
    "#### In order to keep all feature values relatively in the same range, I normalize the range up to -10 to 19 (categoricals go up to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in real_numerics:\n",
    "        \n",
    "    mean_val = train_df[col].mean()\n",
    "    range_val = train_df[col].max()-train_df[col].min()\n",
    "\n",
    "    train[col] = ((train[col]-mean_val)/range_val)*10\n",
    "    validation[col] = ((validation[col]-mean_val)/range_val)*10\n",
    "    test[col] = ((test[col]-mean_val)/range_val)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features Normalization: according to the description file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaningful NaNs: according to the description file. No need to fix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaningful_nans = ['Alley',\n",
    "                   'BsmtQual',\n",
    "                   'BsmtCond',\n",
    "                   'BsmtExposure',\n",
    "                   'BsmtFinType1',\n",
    "                   'BsmtFinType2',\n",
    "                   'FireplaceQu',\n",
    "                   'GarageType',\n",
    "                   'GarageFinish',\n",
    "                   'GarageQual',\n",
    "                   'GarageCond',\n",
    "                   'PoolQC',\n",
    "                   'Fence',\n",
    "                   'MiscFeature']\n",
    "\n",
    "for col in meaningful_nans:\n",
    "    train[col].fillna('NA',inplace=True)\n",
    "    validation[col].fillna('NA',inplace=True)\n",
    "    test[col].fillna('NA',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding for categorical features that cannot be relatively enumerated (e,g. the LandSlope of , moderate, and low can be enumerated to 3,2,1. but it's not the same with MSZoning since non of the categories has a relative value compared with the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['MSZoning',\n",
    "              'LotConfig',\n",
    "              'Neighborhood',\n",
    "              'BldgType',\n",
    "              'HouseStyle',\n",
    "              'RoofStyle',\n",
    "              'RoofMatl',\n",
    "              'MasVnrType',\n",
    "              'Foundation',\n",
    "              'Heating',\n",
    "              'Electrical',\n",
    "              'Functional',\n",
    "              'GarageType',\n",
    "              'MiscFeature',\n",
    "              'SaleType',\n",
    "              'SaleCondition']\n",
    "\n",
    "for col in categories:\n",
    "    one_hot = pd.get_dummies(train_df[col],prefix=col)\n",
    "    try:\n",
    "        one_hot.drop(col+'_NA',axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    train = train.drop(col, axis=1)\n",
    "    train = train.join(one_hot)\n",
    "\n",
    "    for dummy in one_hot.columns:\n",
    "        validation[dummy] = int(dummy in validation[col])\n",
    "        test[dummy] = int(dummy in test[col])\n",
    "\n",
    "    validation = validation.drop(col, axis=1)\n",
    "    test = test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enumerating relative Non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = ['Street',\n",
    "             'Alley',\n",
    "             'LotShape',\n",
    "             'LandContour',\n",
    "             'Utilities',\n",
    "             'LandSlope',\n",
    "             'ExterQual',\n",
    "             'ExterCond',\n",
    "             'BsmtQual',\n",
    "             'BsmtCond',\n",
    "             'BsmtExposure',\n",
    "             'HeatingQC',\n",
    "             'CentralAir',\n",
    "             'KitchenQual',\n",
    "             'FireplaceQu',\n",
    "             'GarageFinish',\n",
    "             'GarageQual',\n",
    "             'GarageCond',\n",
    "             'PavedDrive',\n",
    "             'PoolQC',\n",
    "             'Fence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street, Alley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_cols = ['Street','Alley']\n",
    "enum_dict = {'NA':0,\n",
    "             'Grvl':1,\n",
    "             'Pave':2}\n",
    "\n",
    "for col in enum_cols:\n",
    "    train.replace({col:enum_dict},inplace=True)\n",
    "    validation.replace({col:enum_dict},inplace=True)\n",
    "    test.replace({col:enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Reg':0,\n",
    "             'IR1':1,\n",
    "             'IR2':2,\n",
    "             'IR3':3}\n",
    "\n",
    "train.replace({'LotShape':enum_dict},inplace=True)\n",
    "validation.replace({'LotShape':enum_dict},inplace=True)\n",
    "test.replace({'LotShape':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LandContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Lvl':0,\n",
    "             'Low':1,\n",
    "             'Bnk':2,\n",
    "             'HLS':3}\n",
    "\n",
    "train.replace({'LandContour':enum_dict},inplace=True)\n",
    "validation.replace({'LandContour':enum_dict},inplace=True)\n",
    "test.replace({'LandContour':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'ELO':0,\n",
    "             'NoSeWa':1,\n",
    "             'NoSewr':2,\n",
    "             'AllPub':3}\n",
    "\n",
    "train.replace({'Utilities':enum_dict},inplace=True)\n",
    "validation.replace({'Utilities':enum_dict},inplace=True)\n",
    "test.replace({'Utilities':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LandSlope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Gtl':0,\n",
    "             'Mod':1,\n",
    "             'Sev':2}\n",
    "\n",
    "train.replace({'LandSlope':enum_dict},inplace=True)\n",
    "validation.replace({'LandSlope':enum_dict},inplace=True)\n",
    "test.replace({'LandSlope':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExterQual, ExterCond, BsmtQual, BsmtCond, HeatingQC, KitchenQual, FireplaceQu, GarageQual, GarageCond, PoolQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_cols = ['ExterQual',\n",
    "             'ExterCond', \n",
    "             'BsmtQual', \n",
    "             'BsmtCond', \n",
    "             'HeatingQC', \n",
    "             'KitchenQual', \n",
    "             'FireplaceQu', \n",
    "             'GarageQual', \n",
    "             'GarageCond', \n",
    "             'PoolQC']\n",
    "enum_dict = {'Ex':5,\n",
    "             'Gd':4,\n",
    "             'TA':3,\n",
    "             'Fa':2,\n",
    "             'Po':1,\n",
    "             'NA':0}\n",
    "\n",
    "for col in enum_cols:\n",
    "    train.replace({col:enum_dict},inplace=True)\n",
    "    validation.replace({col:enum_dict},inplace=True)\n",
    "    test.replace({col:enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtExposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Gd':4,\n",
    "             'Av':3,\n",
    "             'Mn':2,\n",
    "             'No':1,\n",
    "             'NA':0}\n",
    "\n",
    "train.replace({'BsmtExposure':enum_dict},inplace=True)\n",
    "validation.replace({'BsmtExposure':enum_dict},inplace=True)\n",
    "test.replace({'BsmtExposure':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CentralAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Y':1,\n",
    "             'N':0}\n",
    "\n",
    "train.replace({'CentralAir':enum_dict},inplace=True)\n",
    "validation.replace({'CentralAir':enum_dict},inplace=True)\n",
    "test.replace({'CentralAir':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Fin':3,\n",
    "             'RFn':2,\n",
    "             'Unf':1,\n",
    "             'NA':0}\n",
    "\n",
    "train.replace({'GarageFinish':enum_dict},inplace=True)\n",
    "validation.replace({'GarageFinish':enum_dict},inplace=True)\n",
    "test.replace({'GarageFinish':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PavedDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'Y':2,\n",
    "             'P':1,\n",
    "             'N':0}\n",
    "\n",
    "train.replace({'PavedDrive':enum_dict},inplace=True)\n",
    "validation.replace({'PavedDrive':enum_dict},inplace=True)\n",
    "test.replace({'PavedDrive':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict = {'GdPrv':4,\n",
    "             'MnPrv':3,\n",
    "             'GdWo':2,\n",
    "             'MnWw':1,\n",
    "             'NA':0}\n",
    "\n",
    "train.replace({'Fence':enum_dict},inplace=True)\n",
    "validation.replace({'Fence':enum_dict},inplace=True)\n",
    "test.replace({'Fence':enum_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Cases\n",
    "#### Merge pairs into one column and then apply multilable binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = ['Condition1','Condition2',\n",
    "        'Exterior1st','Exterior2nd',\n",
    "        'BsmtFinType1','BsmtFinType2']\n",
    "\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition1 and Condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Condition'] = train[['Condition1','Condition2']].apply(lambda row: list(row.values.astype(str)),axis=1)\n",
    "\n",
    "train = train.drop(['Condition1','Condition2'],axis=1)\n",
    "\n",
    "one_hot = pd.DataFrame(mlb.fit_transform(train.pop('Condition')),columns=mlb.classes_,index=train.index).add_prefix('Condition_')\n",
    "\n",
    "train = train.join(one_hot)\n",
    "\n",
    "for dummy in one_hot.columns:\n",
    "        validation[dummy] = int(dummy in validation['Condition1'] or dummy in validation['Condition2'])\n",
    "        test[dummy] = int(dummy in validation['Condition1'] or dummy in validation['Condition2'])\n",
    "\n",
    "validation = validation.drop(['Condition1','Condition2'], axis=1)\n",
    "test = test.drop(['Condition1','Condition2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exterior1st and Exterior2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Exterior'] = train[['Exterior1st','Exterior2nd']].apply(lambda row: list(row.values.astype(str)),axis=1)\n",
    "\n",
    "train = train.drop(['Exterior1st','Exterior2nd'],axis=1)\n",
    "\n",
    "one_hot = pd.DataFrame(mlb.fit_transform(train.pop('Exterior')),columns=mlb.classes_,index=train.index).add_prefix('Exterior_')\n",
    "\n",
    "train = train.join(one_hot)\n",
    "\n",
    "for dummy in one_hot.columns:\n",
    "        validation[dummy] = int(dummy in validation['Exterior1st'] or dummy in validation['Exterior2nd'])\n",
    "        test[dummy] = int(dummy in validation['Exterior1st'] or dummy in validation['Exterior2nd'])\n",
    "\n",
    "validation = validation.drop(['Exterior1st','Exterior2nd'], axis=1)\n",
    "test = test.drop(['Exterior1st','Exterior2nd'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition1 and Condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['BsmtFinType'] = train[['BsmtFinType1','BsmtFinType2']].apply(lambda row: list(row.values.astype(str)),axis=1)\n",
    "\n",
    "train = train.drop(['BsmtFinType1','BsmtFinType2'],axis=1)\n",
    "\n",
    "one_hot = pd.DataFrame(mlb.fit_transform(train.pop('BsmtFinType')),columns=mlb.classes_,index=train.index).add_prefix('BsmtFinType_')\n",
    "\n",
    "train = train.join(one_hot)\n",
    "\n",
    "for dummy in one_hot.columns:\n",
    "        validation[dummy] = int(dummy in validation['BsmtFinType1'] or dummy in validation['BsmtFinType2'])\n",
    "        test[dummy] = int(dummy in validation['BsmtFinType1'] or dummy in validation['BsmtFinType2'])\n",
    "\n",
    "validation = validation.drop(['BsmtFinType1','BsmtFinType2'], axis=1)\n",
    "test = test.drop(['BsmtFinType1','BsmtFinType2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities\tKitchenQual\t"
     ]
    }
   ],
   "source": [
    "for col in test.columns:\n",
    "    if test[col].isnull().values.any():\n",
    "        print(col,end='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities set to electricity only as default (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Utilities'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KitchenQual set to typical/average as default (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['KitchenQual'].fillna(3,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final NaN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SalePrice Normalization\n",
    "#### normalized to the range 0-100 for convergence reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_max = train_df['SalePrice'].max()\n",
    "\n",
    "train['NormalizedPrice'] = (train['SalePrice']/price_max)*100\n",
    "validation['NormalizedPrice'] = (validation['SalePrice']/price_max)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['NormalizedPrice'].copy()\n",
    "y_train_original = train['SalePrice'].copy()\n",
    "x_train = train.drop(columns=['SalePrice','NormalizedPrice'])\n",
    "y_validation = validation['NormalizedPrice'].copy()\n",
    "y_validation_original = validation['SalePrice'].copy()\n",
    "x_validation = validation.drop(columns=['SalePrice','NormalizedPrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4&5. Make the Model and train it\n",
    "#### There are three types of GLM implemented in scikit-learn's linear_model module: \n",
    "#### PoissonRegressor, TweedieRegressor, and GammaRegressor. \n",
    "#### I have experimented all three of them to determine which works best. I also tested out a LinearRegression to see what the results would be like.\n",
    "## NOTICE: For descriptions on parameters, refer to the report pdf!\n",
    "#### To get the optimal parameters for each of the models, I have performed a grid search using GridSearchCV from scikit-learn's model_selection module. This search technique is used for exhaustive search over specified parameter values for an estimator to determine the optimal set of parameters. The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid. GridSearchCV tries out all the possible combinations of the specified parameters and returns the chooses the optimal parameters according to the cross-validation results. GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used. RandomizedSearchCV is another method from scikit-learn's model_selection module that has a similar functionality. The reason I haven't opted for using this method is that in contrast to GridSearchCV, not all parameter values are tried out in this method, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter but why go the extra mile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTICE: An interesting fact\n",
    "### Each time I splitt the data into train and validation, it seems that the distribution varies so much that the results of the GridSearchCV changes drastically. The reason behind this could be the fact that I have used one-hot encoding and increased the number of my features. This results in data sparsity, which might lead to varying distribution over multiple executions. So be mingful that if you run the whole file, results will be different. But the GridSearchCV reveal the same optimal parameters as long as the splitting of data is not altered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoissonRegressor GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.9, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "parameters_psn = {'alpha':[x*0.1 for x in list(range(1,11))],\n",
    "                  'max_iter':[10000]}\n",
    "poisson_best = GridSearchCV(PoissonRegressor(), parameters_psn)\n",
    "poisson_best.fit(x_train, y_train)\n",
    "best_params_psn = poisson_best.best_params_\n",
    "poisson = PoissonRegressor(**best_params_psn)\n",
    "poisson.fit(x_train,y_train)\n",
    "print(best_params_psn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TweedieRegressor GLM\n",
    "#### I experimented with an 'identity' link function and got disasterous results, hence omitted from the parameters list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'link': 'auto', 'max_iter': 10000, 'power': 2}\n"
     ]
    }
   ],
   "source": [
    "parameters_twd = {'power': [0,1,1.5,2,2.5,3],\n",
    "                  'alpha':[x*0.1 for x in list(range(1,11))],\n",
    "                  'link':['auto','log'],\n",
    "                  'max_iter':[10000]}\n",
    "tweedie_best = GridSearchCV(TweedieRegressor(), parameters_twd)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tweedie_best.fit(x_train, y_train)\n",
    "best_params_twd = tweedie_best.best_params_\n",
    "tweedie = TweedieRegressor(**best_params_twd)\n",
    "tweedie.fit(x_train,y_train)\n",
    "print(best_params_twd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GammaRegressor GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'max_iter': 10000}\n"
     ]
    }
   ],
   "source": [
    "parameters_gmm = {'alpha':[x*0.1 for x in list(range(1,11))],\n",
    "                  'max_iter':[10000]}\n",
    "gamma_best = GridSearchCV(GammaRegressor(), parameters_gmm) \n",
    "gamma_best.fit(x_train, y_train)\n",
    "best_params_gmm = gamma_best.best_params_\n",
    "gamma = GammaRegressor(**best_params_gmm)\n",
    "gamma.fit(x_train,y_train)\n",
    "print(best_params_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MSE for train and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoissonRegressor GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE with PoissonRegressor:\t699118107.9345186\n",
      "ValidAaion data MSE with PoissonRegressor:\t1983945887.2347438\n"
     ]
    }
   ],
   "source": [
    "train_prediction_psn = poisson.predict(x_train)*price_max/100\n",
    "train_MSE_psn = mean_squared_error(y_train_original,train_prediction_psn)\n",
    "\n",
    "validation_prediction_psn = poisson.predict(x_validation)*price_max/100\n",
    "validation_MSE_psn = mean_squared_error(y_validation_original,validation_prediction_psn)\n",
    "\n",
    "print('Training data MSE with PoissonRegressor:\\t'+str(train_MSE_psn))\n",
    "print('ValidAaion data MSE with PoissonRegressor:\\t'+str(validation_MSE_psn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TweedieRegressor GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE with TweedieRegressor:\t1597797452.9000711\n",
      "Validation data MSE with TweedieRegressor:\t1090621229.3533208\n"
     ]
    }
   ],
   "source": [
    "train_prediction_twd = tweedie.predict(x_train)*price_max/100\n",
    "train_MSE_twd = mean_squared_error(y_train_original,train_prediction_twd)\n",
    "\n",
    "validation_prediction_twd = tweedie.predict(x_validation)*price_max/100\n",
    "validation_MSE_twd = mean_squared_error(y_validation_original,validation_prediction_twd)\n",
    "\n",
    "print('Training data MSE with TweedieRegressor:\\t'+str(train_MSE_twd))\n",
    "print('Validation data MSE with TweedieRegressor:\\t'+str(validation_MSE_twd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GammaRegressor GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE with GammaRegressor:\t\t1597797452.9000711\n",
      "Validation data MSE with GammaRegressor:\t1090621229.3533208\n"
     ]
    }
   ],
   "source": [
    "train_prediction_gmm = gamma.predict(x_train)*price_max/100\n",
    "train_MSE_gmm = mean_squared_error(y_train_original,train_prediction_gmm)\n",
    "\n",
    "validation_prediction_gmm = gamma.predict(x_validation)*price_max/100\n",
    "validation_MSE_gmm = mean_squared_error(y_validation_original,validation_prediction_gmm)\n",
    "\n",
    "print('Training data MSE with GammaRegressor:\\t\\t'+str(train_MSE_gmm))\n",
    "print('Validation data MSE with GammaRegressor:\\t'+str(validation_MSE_gmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE with LinearRegression:\t517341865.269234\n",
      "Validation data MSE with LinearRegression:\t4415013005.894116\n"
     ]
    }
   ],
   "source": [
    "train_prediction_lr = lr.predict(x_train)*price_max/100\n",
    "train_MSE_lr = mean_squared_error(y_train_original,train_prediction_lr)\n",
    "\n",
    "validation_prediction_lr = lr.predict(x_validation)*price_max/100\n",
    "validation_MSE_lr = mean_squared_error(y_validation_original,validation_prediction_lr)\n",
    "\n",
    "print('Training data MSE with LinearRegression:\\t'+str(train_MSE_lr))\n",
    "print('Validation data MSE with LinearRegression:\\t'+str(validation_MSE_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kaggle Results\n",
    "### Both TweedieRegressor and GammaRegressor reveal exactly the same MSE values which performs slightly better than the PoissonRegressor and LinearRegression. Thus, I chose one of the two models for submision on kaggle. \n",
    "### I have used the trained the model once and then retrained the model with all the data from train and validation.\n",
    "## See the report pdf for results of my submission on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_splitted = tweedie.predict(test)*price_max/100\n",
    "\n",
    "\n",
    "x_whole = pd.concat([x_train,x_validation])\n",
    "y_whole = pd.concat([y_train,y_validation])\n",
    "\n",
    "tweedie_whole = TweedieRegressor(**best_params_twd)\n",
    "tweedie_whole.fit(x_whole, y_whole)\n",
    "\n",
    "prediction_test_whole = tweedie_whole.predict(test)*price_max/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_splitted = pd.DataFrame({'Id':test.index,'SalePrice':prediction_test_splitted})\n",
    "result_whole = pd.DataFrame({'Id':test.index,'SalePrice':prediction_test_whole})\n",
    "\n",
    "result_splitted.to_csv('q3_result_splitted.csv',index=False)\n",
    "result_whole.to_csv('q3_result_whole.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv9f0a0eab11fa4f7d9838725065c25f15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
